% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/semi_supervised.R
\name{predict.clust_analysis}
\alias{predict.clust_analysis}
\alias{predict.min_analysis}
\alias{predict.combi_analysis}
\alias{predict.umatrix_analysis}
\title{Semi-supervised clustering.}
\usage{
\method{predict}{clust_analysis}(
  object,
  newdata = NULL,
  type = c("class", "propagation", "som"),
  active_variables = FALSE,
  ...
)

\method{predict}{min_analysis}(object, ...)

\method{predict}{combi_analysis}(
  object,
  newdata = NULL,
  type = c("class", "propagation", "som"),
  active_variables = FALSE,
  ...
)

\method{predict}{umatrix_analysis}(object, newdata = NULL, ...)
}
\arguments{
\item{object}{an object.}

\item{newdata}{a numeric data frame, matrix or a red_analysis object.
If NULL (default), the bare cluster assignment table is returned.}

\item{type}{type of the projection: simple observation matching
('class', default), kNN label propagation ('propagation') or prediction
via SOM neuronal network ('som'). The SOM prediction method is the sole
prediction algorithm implemented for multi-layer SOM.}

\item{active_variables}{logical, should only active variables be used for the
cluster assignment prediction? Relevant only for objects created with hard threshold regularization algorithms and ignored otherwise  See Details.}

\item{...}{extra arguments passed to \code{\link{propagate}}.}
}
\value{
a \code{\link{clust_analysis}} object.
}
\description{
Projects the cluster assignment onto new data using simple
observation matching, a k-nearest neighbor (kNN) label propagation
algorithm or, specifically for self-organizing map (SOM), predicts the node
assignment based on the trained SOM neuronal network.
}
\details{
For the implementation details of the kNN label propagation
algorithm, see: \code{\link{propagate}}.

The default distance metric is extracted from the \code{clust_analysis} object.
For \code{combi_analysis} objects, the default distance metric is the distance
between observations (not nodes!).
In case of clustering analyses performed with hard threshold regularization
algorithms (currently only \code{\link{htk_cluster}}), the prediction by
the kNN classifier is done by default by using all available variables.
However, by setting \code{active_variables = TRUE}, the user may switch to
prediction of the cluster assignment only with variables contributing to
development of the clustering structure. See the paper by Raymaekers and
Zamar for rationale of the hard thresholding regularization and active
variable selection.

Currently, it is not possible to perform semi-supervised clustering for
clustering analysis objects generated with user-provided dissimilarity
objects (subclass \code{min_analysis} of \code{clust_analysis}). In such cases, \code{NULL}
is returned with a warning.

For the kNN propagation, the cluster projection is done on the top level,
i.e. takes into account the final assignment of the observations to the
clusters and ignoring the SOM nodes.
Predictions via the trained SOM neuronal network are accomplished with
\code{\link{map_som}} (single-layer SOM) or \code{\link{map_supersom}}
(multi-layer SOM), which internally use
the \code{\link[kohonen]{map.kohonen}} function. In this case, the distances,
weights and SOM architecture are extracted from the \code{clust_analysis} or
\code{combi_analysis} object.
If the SOM prediction method is applied to a \code{combi_analysis} object, the
cluster assignment is done in a bottom - top direction: the observations
are mapped onto the SOM nodes and the nodes assigned to the clusters as
specified by the assignment data frame (component \code{clust_assignment} of
the \code{combi_analysis} object).
If the user tries to apply the SOM method with a \code{clust_analysis} method
that was not generated with a non-SOM algorithm, \code{NULL} is returned
with a warning.
The SOM method is also the only method applicable to analyses employing
multi-layer SOM.
}
\references{
Leng M, Wang J, Cheng J, Zhou H, Chen X. Adaptive
semi-supervised clustering algorithm with label propagation.
J Softw Eng (2014) 8:14–22. doi:10.3923/jse.2014.14.22

Kohonen T. Self-Organizing Maps. Berlin, Heidelberg: Springer Berlin
Heidelberg (1995). doi:10.1007/978-3-642-97610-0

Wehrens R, Kruisselbrink J. Flexible self-organizing maps in kohonen 3.0.
J Stat Softw (2018) 87:1–18. doi:10.18637/jss.v087.i07

Raymaekers J, Zamar RH. Regularized K-means Through Hard-Thresholding.
J Mach Learn Res (2022) 23:1–48. Available at:
http://jmlr.org/papers/v23/21-0052.html
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/regularized_clustering.R
\name{htk_cluster}
\alias{htk_cluster}
\alias{tune_htk}
\title{Regularized hard threshold KMEANS clustering.}
\usage{
htk_cluster(
  data,
  k = 2,
  lambdas = NULL,
  select_stat = c("AIC", "BIC"),
  seed = 1234,
  ...
)

tune_htk(
  data,
  k = 2,
  lambdas = NULL,
  select_stat = c("silhouette", "misclassification", "variance", "np"),
  type = c("train", "cv"),
  nfolds = 5,
  kNN = 5,
  simple_vote = TRUE,
  resolve_ties = FALSE,
  kernel_fun = function(x) 1/x,
  kNN_data = 5,
  kNN_cluster = NULL,
  seed = 1234,
  .parallel = FALSE,
  ...
)
}
\arguments{
\item{data}{a numeric data frame with observations in the rows and
variables in the columns.}

\item{k}{number of centers (clusters).}

\item{lambdas}{a numeric vector of the regularization parameter. See Details.}

\item{select_stat}{statistic used for selection of the optimal lambda value.
Ignored if \code{lambdas} is a single numeric value. For \code{htk_cluster()} they are
'AIC' (Akaike Information Criterion) or 'BIC' (Bayesian Information
Criterion). For \code{tune_htk()} they are silhouette width ('silhouette'),
fraction of observations with negative silhouette values
('misclassification'), fraction of explained clustering variance ('variance'),
or neighborhood preservation ('np').}

\item{seed}{root of the random number generator.}

\item{...}{extra arguments provided to \code{\link[clusterHD]{HTKmeans}}.}

\item{type}{type of the tuning procedure. When set to 'train' (default),
cluster structure quality statistics are computed for the entire data set.
When set to 'cv', cross-validated statistics for subsequent lambda values
are calculated.}

\item{nfolds}{number of CV folds.}

\item{kNN}{number of the nearest neighbors used by the cluster assignment
classifier in the cross-validation folds. Ignored if \code{type = 'train'}.}

\item{simple_vote}{logical, should classical unweighted k-NN classification
be applied? If FALSE, distance-weighted k-NN is used with the provided kernel
function. Ignored if \code{type = 'train'}.}

\item{resolve_ties}{logical, should the ties be resolved at random? Applies
only to the simple unweighted voting algorithm. Ignored if \code{type = 'train'}.}

\item{kernel_fun}{kernel function transforming the distance into weight.
Ignored if \code{type = 'train'}.}

\item{kNN_data}{number of the nearest neighbors in the genuine data set
used for calculation of neighborhood preservation. See \code{\link{np}}
for details.}

\item{kNN_cluster}{number of the nearest neighbors of the given cluster used
for calculation of neighborhood preservation. See \code{\link{np}} for
details.}

\item{.parallel}{logical, shoudl the analysis be run in parallel?}
}
\value{
\code{htk_cluster()} returns an object of the
class \code{\link{clust_analysis}}.
}
\description{
Implements the hard threshold KMEANS algorithm proposed by Raymaekers
and Zamar and provided by the \code{clusterHD} package.
}
\details{
The algorithm offers an interesting approach to clustering of
multi-dimensional data, especially those containing variables
of little relevance for the clustering analysis (e.g. as investigated by
permutation importance with \code{\link{impact}}). For details, please refer
to the genuine R function \code{\link[clusterHD]{HTKmeans}} and the seminal
paper. The function works with the squared Euclidean distance metric and
accepts only a numeric data frame as the input data.
There are two crucial parameters to be provided by the user, the number of
centers/clusters \code{k}, which can be determined by methods such as peak mean
silhouette width, and the regularization argument \code{lambdas}, whose value can
be found by tuning (e.g. comparing silhouette widths or clustering variances
for various lambda values). If \code{lambdas} is set to \code{NULL} or provided as
a numeric vector, the best lambda value is found with the
\code{\link[clusterHD]{getLambda}}. If a single value is provided, it
will be used for clustering.
Tuning of the lambda parameter using explained clustering variance,
silhouette widths and neighbor preservation statistic is facilitated by the
\code{tune_htk()} function.
}
\references{
Raymaekers J, Zamar RH. Regularized K-means Through Hard-Thresholding.
J Mach Learn Res (2022) 23:1â€“48.
Available at: http://jmlr.org/papers/v23/21-0052.html
}
